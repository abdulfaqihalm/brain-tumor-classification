{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification Using Fisher Vector as Features Representation and Linear Logistic Regression as Classifier\n",
    "\n",
    "This work is an implementation and modification of [[1]](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0157112) and [[2]](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0140381) in python code (Python was chosen since we wanted to implement a functional web applciation for radiologist. You can see [my repo](https://github.com/abdulfaqihalm/finalProject) to take a look at the web-app). The modification of [[1]](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0157112) and [[2]](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0140381) is only the classifier. The author of [[1]](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0157112) used metric learning - Mahalanobis distance -  to classify the features representation output from Fisher Vectors. Here, we used a simple linear classifier : multi-class logistic regression from sklearn library yet still with a good result. \n",
    "\n",
    "The implementation consists into four steps : \n",
    "1. Tumor region augmentation to obatain valuable information about surrounding tissues\n",
    "2. Subregion local features extraction with spatial division method based on intensity orders\n",
    "3. Fisher vector implementation to obtain single vector representation of subregion local features\n",
    "4. Classification process \n",
    "\n",
    "We used the dataset from [here](https://figshare.com/articles/brain_tumor_dataset/1512427) in .mat format. You will notice that we also used DICOM dataset which was a converted version from .mat file. The reason of that, we wanted to have the [real-case prototype of clinical diagnosis software](https://github.com/abdulfaqihalm/finalProject). The DICOM dataset version can be downloaded from [here](https://drive.google.com/drive/folders/1xMq05zgyZy3ewrHhwAa5heKsnZy2afXp). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, these are links for the dataset and other files which were used for this project : \n",
    "1. [Matlab dataset](https://figshare.com/articles/brain_tumor_dataset/1512427) \n",
    "2. [DICOM dataset](https://drive.google.com/drive/folders/1xMq05zgyZy3ewrHhwAa5heKsnZy2afXp?usp=sharing)\n",
    "3. [Index, label, and trained model's parameters](https://drive.google.com/open?id=1ZtBz3OhThMDQ9vKvWtPEmFHEzOdg6Rtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pydicom\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "from skimage.morphology import disk, binary_dilation \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from cyvlfeat.gmm import gmm\n",
    "from cyvlfeat.fisher import fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary size to be used for GMM learning process\n",
    "dictSize = 64 \n",
    "\n",
    "#Raw image patches size as local features\n",
    "patSize = 7 \n",
    "\n",
    "#Dilation radius of structuring element to augment the tumor region\n",
    "dilationRad = 2 \n",
    "\n",
    "#Subregion of intensity based (i.e. for maximum intensity value 80, , it will devide the features\n",
    "#into several regions. There are : 0-10, 11-20, .. 71-80) \n",
    "nRegion = 8 \n",
    "\n",
    "filePath= <Your .mat path>\n",
    "dicomPath = <Your DICOM path>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Normalization \n",
    "The normalization of dataset uses rescalling method(min-max normalization) to rescale the intensity value of 16 bit MRI T1 images.\n",
    "\n",
    "## Tumor Patches Extraction \n",
    "The local descriptors of the tumor region use raw image patches to be encoded to the higher level features by Fisher Vector. Since the raw patches is simple, yet,  sufficiently efficient for image classification, it can  reduce the complexity of the process of feature extraction and improve computing efficiency.You can read further information about the raw patches local descriptors for Fisher Vector in [this paper](https://www.mdpi.com/2078-2489/9/2/38/htm).\n",
    "\n",
    "![](img/ImagePatches.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image normalization using \n",
    "def norm(image):\n",
    "    minElm = np.amin(image)\n",
    "    maxElm = np.amax(image)\n",
    "    normImage = np.true_divide((np.subtract(image, minElm)), (maxElm - minElm))\n",
    "    return normImage \n",
    "\n",
    "#Tumor region patches for visual words vocabulary \n",
    "def extractLocTrainFeas(normImage, dilMask, patSize):\n",
    "    (r, c) = np.float32(dilMask.nonzero())\n",
    "    offset = (patSize-1)/2\n",
    "    x = np.linspace(-offset, offset, patSize, dtype='float32')\n",
    "    [x, y] = np.meshgrid (x, x)\n",
    "    rDelta = x \n",
    "    cDelta = y\n",
    "    feas = np.zeros((patSize**2, c.size), dtype='float32')\n",
    "    n = 0 \n",
    "    for i in range(patSize):\n",
    "        for j in range(patSize):\n",
    "            rShifted = r + rDelta[i, j]\n",
    "            cShifted = c + cDelta[i, j]      \n",
    "            feas[n, :] = normImage[rShifted.astype(int), cShifted.astype(int)]\n",
    "            n += 1 \n",
    "    len = int((np.size(feas, 1)-1)/5)\n",
    "    arr = np.random.permutation(np.size(feas, 1))[0:len]\n",
    "    feas = feas[:, arr]\n",
    "    return feas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Label and Index\n",
    "To train the model, we only used the single validation using index 1. In this work, we converted the index and label to .npz for convenience. You can download the label, index and other model parameters at [this link](https://drive.google.com/open?id=1ZtBz3OhThMDQ9vKvWtPEmFHEzOdg6Rtm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determining the index for testing and training \n",
    "index = np.load('cvIndex.npz')\n",
    "index = index['cvind']\n",
    "    \n",
    "# Index 1 for training and other for testing \n",
    "testInd = np.uint16(np.where(index==(1))[1])\n",
    "trainInd = np.uint16(np.where(index!=(1))[1])\n",
    "\n",
    "# Loading label \n",
    "label = np.load('label.npz')\n",
    "label = label['label']\n",
    "\n",
    "trainLabel = label[trainInd]\n",
    "testLabel = label[testInd]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Local Features from Training set\n",
    "This cell will loop through training set to extract and append the local features. The local features consist of tumor patches of images. The local features matrix size is 49xN where 49 comes from the numbers of patches and N comes from the total tumor pixel of all images which appended. \n",
    "To reduce the computation resources, we pick 300000 coloumns randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 2478945)\n",
      "(49, 300000)\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "n = 0\n",
    "for i in trainInd:\n",
    "    print(\"{}-th Iteration \".format(n))\n",
    "    arrays = {}\n",
    "    arr = {}\n",
    "    normImage = np.empty([2,2])\n",
    "    f = h5py.File(os.path.join(filePath,str(i+1)+\".mat\"),'a')\n",
    "    for k, v in f.items() : \n",
    "        arrays[k] = np.array(v)\n",
    "        for i, j in v.items() : \n",
    "            arr[i] = np.array(j, dtype=np.float32)\n",
    "    image = arr['image']\n",
    "    mask = arr['tumorMask']\n",
    "    normImage = norm(image)\n",
    "    normImage = np.fliplr(np.rot90(normImage,1,(1,0)))\n",
    "    mask = np.fliplr(np.rot90(mask,1,(1,0)))\n",
    "    se = disk(dilationRad)\n",
    "    dilMask = binary_dilation(mask, se)\n",
    "    feas = extractLocTrainFeas(normImage, dilMask, patSize)\n",
    "    temp.append(feas)\n",
    "    n = n+1\n",
    "\n",
    "cluFeas = np.empty([49, 0], dtype='float32')\n",
    "for i in range (trainInd.shape[0]):\n",
    "    x = np.array(temp[i])\n",
    "    cluFeas = np.append(cluFeas, x, axis=1)\n",
    "print(cluFeas.shape)\n",
    "\n",
    "#Intended to reduce the computation complexity. Therefore, we needed just 300000 features from extracted local features.\n",
    "#You can change the value if you want to expand or reduce the features\n",
    "arr = np.random.permutation(np.size(cluFeas, 1))[0:300000]\n",
    "cluFeas = cluFeas[:, arr]\n",
    "print(cluFeas.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Reduction \n",
    "To reduce the computation, we also reduced the dimension of features using PCA. Here, we only considered the number of features dimension from the 99% cumulative percentage of its eigenvalue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can reduce to 8-th first features.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validating how many components must be included\n",
    "pca = PCA(svd_solver='full') \n",
    "# Transpose to make the dense patches as a measurement variables\n",
    "pca.fit(cluFeas.transpose())\n",
    "\n",
    "x = np.arange(1, 21)\n",
    "y = np.cumsum(pca.explained_variance_ratio_[:20])\n",
    "\n",
    "# Finding the index of cumulative percentage of eigenvalue where the cum > 99%\n",
    "compIndex = np.where(np.cumsum(pca.explained_variance_ratio_[:20])>0.99)[0][0]\n",
    "print(\"We can reduce to {}-th first features.\".format(compIndex+1))\n",
    "\n",
    "# Plotting the eigenValue cumulative percentage\n",
    "plt.figure(figsize=(20,10)) \n",
    "plt.step(x, y)\n",
    "for i_x, i_y in zip(x, y):\n",
    "    plt.text(i_x, i_y-0.01, '{}'.format(i_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score shape : \n",
      "(300000, 8)\n",
      "\n",
      "Score 1st row : \n",
      "[-0.00544921  0.43438402 -0.316197   -0.10672852 -0.0651527   0.01000253\n",
      " -0.05464405  0.02541979]\n",
      "\n",
      "Truncated Eigenvalue : \n",
      "[0.7606879  0.03957978 0.0375922  0.0090944  0.00817247 0.0056915\n",
      " 0.00314325 0.002553  ]\n"
     ]
    }
   ],
   "source": [
    "# Average of each row of cluFeas \n",
    "cluFeasAvg = np.mean(cluFeas, 1)\n",
    "\n",
    "# Transforming the features and truncating\n",
    "pca = PCA(n_components=(compIndex+1), svd_solver='full')\n",
    "pca.fit(cluFeas.transpose())\n",
    "score = pca.fit_transform(cluFeas.transpose())\n",
    "principalComp = pca.components_\n",
    "print('Score shape : ')\n",
    "print(score.shape)\n",
    "print('\\nScore 1st row : ')\n",
    "print(score[0])\n",
    "print('\\nTruncated Eigenvalue : ')\n",
    "print(pca.explained_variance_)\n",
    "\n",
    "# Saving the score and princComp\n",
    "np.savez_compressed('score.npz', score=score)\n",
    "np.savez_compressed('principalComp.npz', principalComp=principalComp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Models\n",
    "To find the Fisher Vectors, we determined the generative model (a GMM) which approximates the distribution of low-level features (visual vocabolaries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vl_gmm: vl_init_mode = rand\n",
      "vl_gmm: maxNumIterations = 500\n",
      "vl_gmm: numRepetitions = 1\n",
      "vl_gmm: data type = float\n",
      "vl_gmm: data n_features = 8\n",
      "vl_gmm: num. data points = 300000\n",
      "vl_gmm: num. Gaussian modes = 64\n",
      "vl_gmm: lower bound on covariance = [ 0.000100 0.000100 ... 0.000100]\n",
      "gmm: clustering: starting repetition 1 of 1\n",
      "gmm: model initialized in 0.15 s\n",
      "gmm: em: iteration 0: loglikelihood = 1365957.648621 (variation = inf)\n",
      "gmm: em: iteration 1: loglikelihood = 2214258.944451 (variation = 848301.295830)\n",
      "gmm: em: iteration 2: loglikelihood = 2383974.995216 (variation = 169716.050765)\n",
      "gmm: sparsity of data posterior: 85.6%\n",
      "gmm: em: iteration 3: loglikelihood = 2445316.734580 (variation = 61341.739364)\n",
      "gmm: sparsity of data posterior: 86.4%\n",
      "gmm: em: iteration 4: loglikelihood = 2465551.574552 (variation = 20234.839973)\n",
      "gmm: sparsity of data posterior: 86.7%\n",
      "gmm: em: iteration 5: loglikelihood = 2475566.065120 (variation = 10014.490568)\n",
      "gmm: sparsity of data posterior: 86.9%\n",
      "gmm: em: iteration 6: loglikelihood = 2482616.133501 (variation = 7050.068381)\n",
      "gmm: sparsity of data posterior: 87.1%\n",
      "gmm: em: iteration 7: loglikelihood = 2488115.124098 (variation = 5498.990596)\n",
      "gmm: sparsity of data posterior: 87.3%\n",
      "gmm: em: iteration 8: loglikelihood = 2492316.054525 (variation = 4200.930427)\n",
      "gmm: sparsity of data posterior: 87.5%\n",
      "gmm: em: iteration 9: loglikelihood = 2495486.761894 (variation = 3170.707370)\n",
      "gmm: sparsity of data posterior: 87.7%\n",
      "gmm: em: iteration 10: loglikelihood = 2497907.232170 (variation = 2420.470276)\n",
      "gmm: sparsity of data posterior: 87.9%\n",
      "gmm: em: iteration 11: loglikelihood = 2499788.245320 (variation = 1881.013150)\n",
      "gmm: sparsity of data posterior: 88.0%\n",
      "gmm: em: iteration 12: loglikelihood = 2501285.546394 (variation = 1497.301074)\n",
      "gmm: sparsity of data posterior: 88.2%\n",
      "gmm: em: iteration 13: loglikelihood = 2502514.906472 (variation = 1229.360078)\n",
      "gmm: sparsity of data posterior: 88.3%\n",
      "gmm: em: iteration 14: loglikelihood = 2503556.505441 (variation = 1041.598968)\n",
      "gmm: sparsity of data posterior: 88.4%\n",
      "gmm: em: iteration 15: loglikelihood = 2504464.106512 (variation = 907.601072)\n",
      "gmm: sparsity of data posterior: 88.5%\n",
      "gmm: em: iteration 16: loglikelihood = 2505271.391606 (variation = 807.285093)\n",
      "gmm: sparsity of data posterior: 88.5%\n",
      "gmm: em: iteration 17: loglikelihood = 2506001.468042 (variation = 730.076436)\n",
      "gmm: sparsity of data posterior: 88.6%\n",
      "gmm: em: iteration 18: loglikelihood = 2506668.783943 (variation = 667.315901)\n",
      "gmm: sparsity of data posterior: 88.7%\n",
      "gmm: em: iteration 19: loglikelihood = 2507284.070139 (variation = 615.286196)\n",
      "gmm: sparsity of data posterior: 88.8%\n",
      "gmm: em: iteration 20: loglikelihood = 2507854.829188 (variation = 570.759048)\n",
      "gmm: sparsity of data posterior: 88.8%\n",
      "gmm: em: iteration 21: loglikelihood = 2508385.385888 (variation = 530.556700)\n",
      "gmm: sparsity of data posterior: 88.9%\n",
      "gmm: em: iteration 22: loglikelihood = 2508878.884564 (variation = 493.498676)\n",
      "gmm: sparsity of data posterior: 89.0%\n",
      "gmm: em: iteration 23: loglikelihood = 2509337.967875 (variation = 459.083311)\n",
      "gmm: sparsity of data posterior: 89.0%\n",
      "gmm: em: iteration 24: loglikelihood = 2509764.876558 (variation = 426.908683)\n",
      "gmm: sparsity of data posterior: 89.1%\n",
      "gmm: em: iteration 25: loglikelihood = 2510161.079849 (variation = 396.203290)\n",
      "gmm: sparsity of data posterior: 89.2%\n",
      "gmm: em: iteration 26: loglikelihood = 2510529.535069 (variation = 368.455220)\n",
      "gmm: sparsity of data posterior: 89.2%\n",
      "gmm: em: iteration 27: loglikelihood = 2510871.962469 (variation = 342.427400)\n",
      "gmm: sparsity of data posterior: 89.3%\n",
      "gmm: em: iteration 28: loglikelihood = 2511191.188870 (variation = 319.226401)\n",
      "gmm: sparsity of data posterior: 89.3%\n",
      "gmm: em: iteration 29: loglikelihood = 2511489.307599 (variation = 298.118729)\n",
      "gmm: sparsity of data posterior: 89.4%\n",
      "gmm: em: iteration 30: loglikelihood = 2511769.265987 (variation = 279.958388)\n",
      "gmm: sparsity of data posterior: 89.4%\n",
      "gmm: em: iteration 31: loglikelihood = 2512032.584077 (variation = 263.318090)\n",
      "gmm: sparsity of data posterior: 89.4%\n",
      "gmm: em: iteration 32: loglikelihood = 2512281.710985 (variation = 249.126908)\n",
      "gmm: sparsity of data posterior: 89.5%\n",
      "gmm: em: iteration 33: loglikelihood = 2512518.112939 (variation = 236.401954)\n",
      "gmm: sparsity of data posterior: 89.5%\n",
      "gmm: em: iteration 34: loglikelihood = 2512743.160055 (variation = 225.047116)\n",
      "gmm: sparsity of data posterior: 89.5%\n",
      "gmm: em: iteration 35: loglikelihood = 2512957.807511 (variation = 214.647456)\n",
      "gmm: sparsity of data posterior: 89.6%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 36: loglikelihood = 2513162.232716 (variation = 204.425205)\n",
      "gmm: sparsity of data posterior: 89.6%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 37: loglikelihood = 2513357.575948 (variation = 195.343232)\n",
      "gmm: sparsity of data posterior: 89.6%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 38: loglikelihood = 2513543.779271 (variation = 186.203323)\n",
      "gmm: sparsity of data posterior: 89.7%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 39: loglikelihood = 2513721.040837 (variation = 177.261567)\n",
      "gmm: sparsity of data posterior: 89.7%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 40: loglikelihood = 2513889.786139 (variation = 168.745302)\n",
      "gmm: sparsity of data posterior: 89.7%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 41: loglikelihood = 2514050.484607 (variation = 160.698468)\n",
      "gmm: sparsity of data posterior: 89.7%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 42: loglikelihood = 2514203.652447 (variation = 153.167840)\n",
      "gmm: sparsity of data posterior: 89.7%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 43: loglikelihood = 2514349.936877 (variation = 146.284430)\n",
      "gmm: sparsity of data posterior: 89.8%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 44: loglikelihood = 2514489.514062 (variation = 139.577185)\n",
      "gmm: sparsity of data posterior: 89.8%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 45: loglikelihood = 2514623.266355 (variation = 133.752293)\n",
      "gmm: sparsity of data posterior: 89.8%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 46: loglikelihood = 2514751.867965 (variation = 128.601610)\n",
      "gmm: sparsity of data posterior: 89.8%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 47: loglikelihood = 2514875.813101 (variation = 123.945136)\n",
      "gmm: sparsity of data posterior: 89.8%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 48: loglikelihood = 2514996.046744 (variation = 120.233643)\n",
      "gmm: sparsity of data posterior: 89.8%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 49: loglikelihood = 2515113.009836 (variation = 116.963092)\n",
      "gmm: sparsity of data posterior: 89.9%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 50: loglikelihood = 2515227.298142 (variation = 114.288306)\n",
      "gmm: sparsity of data posterior: 89.9%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 51: loglikelihood = 2515339.594739 (variation = 112.296596)\n",
      "gmm: sparsity of data posterior: 89.9%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 52: loglikelihood = 2515450.126051 (variation = 110.531312)\n",
      "gmm: sparsity of data posterior: 89.9%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 53: loglikelihood = 2515559.919042 (variation = 109.792991)\n",
      "gmm: sparsity of data posterior: 89.9%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 54: loglikelihood = 2515668.283341 (variation = 108.364299)\n",
      "gmm: sparsity of data posterior: 89.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 55: loglikelihood = 2515775.491758 (variation = 107.208417)\n",
      "gmm: sparsity of data posterior: 89.9%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 56: loglikelihood = 2515880.116433 (variation = 104.624675)\n",
      "gmm: sparsity of data posterior: 89.9%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 57: loglikelihood = 2515982.123785 (variation = 102.007351)\n",
      "gmm: sparsity of data posterior: 89.9%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 58: loglikelihood = 2516079.656820 (variation = 97.533036)\n",
      "gmm: sparsity of data posterior: 89.9%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 59: loglikelihood = 2516172.231363 (variation = 92.574543)\n",
      "gmm: sparsity of data posterior: 89.9%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 60: loglikelihood = 2516259.018672 (variation = 86.787309)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 61: loglikelihood = 2516339.912290 (variation = 80.893618)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 62: loglikelihood = 2516415.544456 (variation = 75.632166)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 63: loglikelihood = 2516486.217876 (variation = 70.673421)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 64: loglikelihood = 2516552.688119 (variation = 66.470242)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 65: loglikelihood = 2516615.611487 (variation = 62.923368)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 66: loglikelihood = 2516675.657267 (variation = 60.045780)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 67: loglikelihood = 2516733.501707 (variation = 57.844440)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 68: loglikelihood = 2516789.396026 (variation = 55.894320)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 69: loglikelihood = 2516843.911663 (variation = 54.515637)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 70: loglikelihood = 2516897.242338 (variation = 53.330674)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 71: loglikelihood = 2516949.464014 (variation = 52.221677)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 72: loglikelihood = 2517000.874976 (variation = 51.410962)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 73: loglikelihood = 2517051.111504 (variation = 50.236528)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 74: loglikelihood = 2517100.849813 (variation = 49.738309)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 75: loglikelihood = 2517149.403043 (variation = 48.553229)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 76: loglikelihood = 2517196.934882 (variation = 47.531839)\n",
      "gmm: sparsity of data posterior: 90.0%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 77: loglikelihood = 2517243.697440 (variation = 46.762559)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 78: loglikelihood = 2517289.243675 (variation = 45.546234)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 79: loglikelihood = 2517333.825353 (variation = 44.581678)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 80: loglikelihood = 2517377.808710 (variation = 43.983357)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 81: loglikelihood = 2517420.752583 (variation = 42.943873)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 82: loglikelihood = 2517463.186031 (variation = 42.433448)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 83: loglikelihood = 2517504.974770 (variation = 41.788739)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 84: loglikelihood = 2517546.400165 (variation = 41.425396)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 85: loglikelihood = 2517587.383878 (variation = 40.983713)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 86: loglikelihood = 2517628.642605 (variation = 41.258727)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 87: loglikelihood = 2517669.751686 (variation = 41.109081)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 88: loglikelihood = 2517710.646296 (variation = 40.894610)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 89: loglikelihood = 2517751.893990 (variation = 41.247693)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 90: loglikelihood = 2517793.351849 (variation = 41.457859)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 91: loglikelihood = 2517835.198422 (variation = 41.846573)\n",
      "gmm: sparsity of data posterior: 90.1%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 92: loglikelihood = 2517877.038706 (variation = 41.840285)\n",
      "gmm: sparsity of data posterior: 90.2%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 93: loglikelihood = 2517919.655426 (variation = 42.616720)\n",
      "gmm: sparsity of data posterior: 90.2%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 94: loglikelihood = 2517962.498771 (variation = 42.843345)\n",
      "gmm: sparsity of data posterior: 90.2%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 95: loglikelihood = 2518006.097049 (variation = 43.598278)\n",
      "gmm: sparsity of data posterior: 90.2%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 96: loglikelihood = 2518049.958285 (variation = 43.861236)\n",
      "gmm: sparsity of data posterior: 90.2%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 97: loglikelihood = 2518094.449675 (variation = 44.491390)\n",
      "gmm: sparsity of data posterior: 90.2%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 98: loglikelihood = 2518139.461406 (variation = 45.011731)\n",
      "gmm: sparsity of data posterior: 90.2%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 99: loglikelihood = 2518185.092680 (variation = 45.631274)\n",
      "gmm: sparsity of data posterior: 90.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 100: loglikelihood = 2518231.026368 (variation = 45.933689)\n",
      "gmm: sparsity of data posterior: 90.2%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 101: loglikelihood = 2518277.331723 (variation = 46.305354)\n",
      "gmm: sparsity of data posterior: 90.2%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 102: loglikelihood = 2518324.051233 (variation = 46.719511)\n",
      "gmm: sparsity of data posterior: 90.2%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 103: loglikelihood = 2518370.800876 (variation = 46.749643)\n",
      "gmm: sparsity of data posterior: 90.2%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 104: loglikelihood = 2518417.510608 (variation = 46.709732)\n",
      "gmm: sparsity of data posterior: 90.3%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 105: loglikelihood = 2518464.033593 (variation = 46.522985)\n",
      "gmm: sparsity of data posterior: 90.3%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 106: loglikelihood = 2518510.109433 (variation = 46.075840)\n",
      "gmm: sparsity of data posterior: 90.3%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 107: loglikelihood = 2518555.458348 (variation = 45.348915)\n",
      "gmm: sparsity of data posterior: 90.3%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 108: loglikelihood = 2518599.948765 (variation = 44.490418)\n",
      "gmm: sparsity of data posterior: 90.3%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 109: loglikelihood = 2518643.111193 (variation = 43.162427)\n",
      "gmm: sparsity of data posterior: 90.3%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 110: loglikelihood = 2518685.289096 (variation = 42.177903)\n",
      "gmm: sparsity of data posterior: 90.3%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 111: loglikelihood = 2518726.067814 (variation = 40.778719)\n",
      "gmm: sparsity of data posterior: 90.3%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 112: loglikelihood = 2518765.105858 (variation = 39.038044)\n",
      "gmm: sparsity of data posterior: 90.3%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 113: loglikelihood = 2518803.043701 (variation = 37.937842)\n",
      "gmm: sparsity of data posterior: 90.3%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 114: loglikelihood = 2518839.265084 (variation = 36.221384)\n",
      "gmm: sparsity of data posterior: 90.3%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 115: loglikelihood = 2518874.093348 (variation = 34.828264)\n",
      "gmm: sparsity of data posterior: 90.3%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 116: loglikelihood = 2518907.776348 (variation = 33.682999)\n",
      "gmm: sparsity of data posterior: 90.4%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 117: loglikelihood = 2518939.963370 (variation = 32.187023)\n",
      "gmm: sparsity of data posterior: 90.4%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 118: loglikelihood = 2518971.298500 (variation = 31.335130)\n",
      "gmm: sparsity of data posterior: 90.4%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 119: loglikelihood = 2519001.254138 (variation = 29.955637)\n",
      "gmm: sparsity of data posterior: 90.4%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 120: loglikelihood = 2519030.532869 (variation = 29.278732)\n",
      "gmm: sparsity of data posterior: 90.4%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 121: loglikelihood = 2519058.580664 (variation = 28.047795)\n",
      "gmm: sparsity of data posterior: 90.4%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 122: loglikelihood = 2519086.136762 (variation = 27.556098)\n",
      "gmm: sparsity of data posterior: 90.4%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 123: loglikelihood = 2519112.655672 (variation = 26.518910)\n",
      "gmm: sparsity of data posterior: 90.4%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 124: loglikelihood = 2519138.835957 (variation = 26.180285)\n",
      "gmm: sparsity of data posterior: 90.4%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 125: loglikelihood = 2519164.333382 (variation = 25.497425)\n",
      "gmm: sparsity of data posterior: 90.4%\n",
      "gmm: detected 1 of 64 modes with at least one dimension with covariance too small (set to lower bound)\n",
      "gmm: em: iteration 126: loglikelihood = 2519189.372710 (variation = 25.039329)\n",
      "gmm: em: terminating because the algorithm fully converged (log-likelihood variation = 0.000010).\n",
      "gmm: optimization terminated in 29.47 s with loglikelihood 2519189.372710\n",
      "gmm: all repetitions terminated with final loglikelihood 2519189.372710\n"
     ]
    }
   ],
   "source": [
    "# Finding the Gaussian Mixture Models\n",
    "# The Outputs type all in as score.dtype\n",
    "[means, covariances, priors, LL, posteriors] = gmm(score, dictSize, verbose=True, max_num_iterations=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subregion extraction \n",
    "The reason why we pooled the tumor region into intensity-based is to obtain the both spatial information and intesity distributions. Hence, we could obtain more representative and discriminative features.\n",
    "You can read more about subregion intensity-based features extraction from [[4]](https://ieeexplore.ieee.org/abstract/document/5995385)\n",
    "\n",
    "![](img/Subregion.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the region index \n",
    "def regionInd(normImage, dilMask, nRegion):\n",
    "    intensities = normImage[dilMask]\n",
    "    quantiles = np.float32(np.quantile(intensities, np.linspace(0, 1, nRegion+1)))\n",
    "    regInd = np.zeros(intensities.size)\n",
    "    for i in range (nRegion):\n",
    "        ind = np.logical_and((intensities>=quantiles[i]), (intensities<=quantiles[i+1]))\n",
    "        regInd[ind] = i\n",
    "    return regInd\n",
    "\n",
    "# Extract local feas for all images (train and test)\n",
    "def extractLocFeasAll(normImage, dilMask, patSize):\n",
    "    (r, c) = np.float32(dilMask.nonzero())\n",
    "    offset = (patSize-1)/2\n",
    "    x = np.linspace(-offset, offset, patSize, dtype='float32')\n",
    "    [x, y] = np.meshgrid (x, x)\n",
    "    rDelta = x \n",
    "    cDelta = y\n",
    "    feas = np.zeros((patSize**2, c.size), dtype='float32')\n",
    "    n = 0 \n",
    "    for i in range(patSize):\n",
    "        for j in range(patSize):\n",
    "            rShifted = r + rDelta[i, j]\n",
    "            cShifted = c + cDelta[i, j]      \n",
    "            feas[n, :] = normImage[rShifted.astype(int), cShifted.astype(int)]\n",
    "            n += 1 \n",
    "    return feas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Fisher Vector \n",
    "According to vlfeaat.org, The Fisher kernel is a powerful framework which combines the strengths of generative and discriminative approaches to pattern classiﬁcation [[5]](https://ieeexplore.ieee.org/document/4270291). The idea is to characterize a signal with a gradient vector derived from a probability density function(pdf) which models the generation process of the signal. For the problem of image categorization the inputs ignals are images and use generative model GMM which approximates the distribution of low-level features in images.\n",
    "<p>Let \\(I = (\\bf{x_1},\\dots,\\bf{x_N})\\) be a set of \\(D\\) dimensional feature vectors extracted from an image. Let \\(\\Theta=(\\mu_k,\\Sigma_k,\\pi_k:k=1,\\dots,K)\\) be the parameters of a Gaussian Mixture Model fitting the distribution of descriptors. The GMM associates each vector \\(\\bf{x_i}\\) to a mode \\(k\\) in the mixture with a strength given by the posterior probability:</p>\n",
    "<p class=\"formulaDsp\">\n",
    "\\[ q_{ik} = \\frac {\\exp\\left[-\\frac{1}{2}(\\bf{x_i} - \\mu_k)^T \\Sigma_k^{-1} (\\bf{x_i} - \\mu_k)\\right]} {\\sum_{t=1}^K \\exp\\left[-\\frac{1}{2}(\\bf{x_i} - \\mu_t)^T \\Sigma_k^{-1} (\\bf{x_i} - \\mu_t)\\right]}. \\]\n",
    "</p>\n",
    "<p>For each mode \\(k\\), consider the mean and covariance deviation vectors</p>\n",
    "<p class=\"formulaDsp\">\n",
    "\\begin{align*} u_{jk} = {1 \\over {N \\sqrt{\\pi_k}}} \\sum_{i=1}^{N} q_{ik} \\frac{x_{ji} - \\mu_{jk}}{\\sigma_{jk}}, \\\\ v_{jk} = {1 \\over {N \\sqrt{2 \\pi_k}}} \\sum_{i=1}^{N} q_{ik} \\left[ \\left(\\frac{x_{ji} - \\mu_{jk}}{\\sigma_{jk}}\\right)^2 - 1 \\right]. \\end{align*}\n",
    "</p>\n",
    "<p>where \\(j=1,2,\\dots,D\\) spans the vector dimensions. The FV of image \\(I\\) is the stacking of the vectors \\(\\bf{u_k}\\) and then of the vectors \\(\\bf{v_k}\\) for each of the \\(K\\) modes in the Gaussian mixtures:</p>\n",
    "<p class=\"formulaDsp\">\n",
    "\\[ \\Phi(I) = \\begin{bmatrix} \\vdots \\\\ \\bf{u_k} \\\\ \\vdots \\\\ \\bf{v_k} \\\\ \\vdots \\end{bmatrix}. \\]\n",
    "</p>\n",
    "\n",
    "\n",
    "The Improved Fisher Vector [[6]](https://www.robots.ox.ac.uk/~vgg/rg/papers/peronnin_etal_ECCV10.pdf) using the ideas : \n",
    "1. Non-linear additive kernel. The Hellinger's kernel (or Bhattacharya coefficient) can be used instead of the linear one at no cost by signed squared rooting. This is obtained by applying the function |z|signz to each dimension of the vector Φ(I). Other additive kernels can also be used at an increased space or time cost.\n",
    "2. Normalization. Before using the representation in a linear model (e.g. a support vector machine), the vector Φ(I) is further normalized by the l2 norm (note that the standard Fisher vector is normalized by the number of encoded feature vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192, 3064)\n"
     ]
    }
   ],
   "source": [
    "# If compIndex+1 = 8, so the size of feaMat = 8*2*64*8 x 3064 = 8192 x 3064\n",
    "feaMat = np.empty(((compIndex+1) * 2 * dictSize * nRegion, 0), dtype='float32')\n",
    "for i in range(3064):\n",
    "    temp = []\n",
    "    arrays = {}\n",
    "    arr = {}\n",
    "    normImage = np.empty([2,2])\n",
    "    image = pydicom.filereader.dcmread(os.path.join(dicomPath,str(i+1)+\".dcm\")).pixel_array\n",
    "    f = h5py.File(os.path.join(filePath,str(i+1)+\".mat\"),'a')\n",
    "    for k, v in f.items() : \n",
    "        arrays[k] = np.array(v)\n",
    "        for i, j in v.items() : \n",
    "            arr[i] = np.array(j, dtype=np.float32)\n",
    "    mask = arr['tumorMask']\n",
    "    normImage = norm(image)\n",
    "    mask = np.fliplr(np.rot90(mask,1,(1,0)))\n",
    "    se = disk(dilationRad)\n",
    "    dilMask = binary_dilation(mask, se)\n",
    "    feas = extractLocFeasAll(normImage, dilMask, patSize)\n",
    "    feas = np.matmul(principalComp,(feas - cluFeasAvg[:,None]))\n",
    "    regInd = regionInd(normImage, dilMask, nRegion)\n",
    "    for j in range(nRegion):\n",
    "        temp = np.append(temp, fisher(feas[::, regInd==j], means.transpose(), \n",
    "                     covariances.transpose(), priors.transpose(),improved=True))\n",
    "    feaMat = np.append(feaMat, temp[:,np.newaxis], axis=1)\n",
    "print(feaMat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeaMat = feaMat[:, trainInd]\n",
    "testFeaMat = feaMat[:, testInd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification \n",
    "Since the Improved Fisher Vectors are linearly separable, we used logistic regression to classify the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "logreg.fit(trainFeaMat.T, np.ravel(trainLabel))\n",
    "prediction = logreg.predict(testFeaMat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 396x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per class : [0.85416667 0.96538462 0.87349398]\n",
      "Recall per class : [0.86013986 0.95075758 0.88957055]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(testLabel, prediction)\n",
    "[prec, recall, fscore, support] = precision_recall_fscore_support(testLabel, prediction)\n",
    "\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['Meningioma','Glioma','Pituary'], \n",
    "                     columns = ['Meningioma','Glioma','Pituary'])\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Evaluation Performance \\nSystem Accuracy:{0:.3f}'.format(accuracy_score(testLabel, prediction)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "print('Precision per class : {}'.format(prec))\n",
    "print('Recall per class : {}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1]  [Cheng, Jun, et al. \"Retrieval of Brain Tumors by Adaptive Spatial Pooling and Fisher Vector Representation.\" PloS one 11.6 (2016).](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0157112) \n",
    "\n",
    "[2]  [Cheng, Jun, et al. \"Enhanced Performance of Brain Tumor Classification via Tumor Region Augmentation and Partition\" PloS one 10.8 (2015).](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0140381) \n",
    "\n",
    "[3]  [C. Shuangshuang, et al. \"Local Patch Vectors Encoded by Fisher Vectors for Image Classification\" MDPI 12.22 (2017).](https://www.mdpi.com/2078-2489/9/2/38/htm)\n",
    "\n",
    "[4]  [B. Fan, et al. \"Aggregating gradient distributions into intensity orders: A novel local image descriptor\" IEEE (2011)](https://ieeexplore.ieee.org/abstract/document/5995385)\n",
    "\n",
    "[5]  [P. Florent, D. Christopher. \"Fisher Kernels on Visual Vocabularies for Image Categorization\" Xerox Research Center (2011)](https://ieeexplore.ieee.org/document/4270291)\n",
    "\n",
    "[5]  [P. Florent, s. Jorge, M. Thomas. \"Improving the fisher kernel for large-scale image classification\" ECCV (2010)](https://www.robots.ox.ac.uk/~vgg/rg/papers/peronnin_etal_ECCV10.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
